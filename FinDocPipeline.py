import streamlit as st
import pandas as pd
import tempfile
from datetime import datetime
import os
import re
import subprocess
import sys

class FinancialDocumentETL:
    """Pure ETL for financial document data extraction and transformation"""
    
    def __init__(self):
        self.pdf_methods = []
        self._check_available_methods()
    
    def _check_available_methods(self):
        """Check which PDF processing methods are available"""
        try:
            import pdfplumber
            self.pdf_methods.append('pdfplumber')
        except ImportError:
            pass
        
        try:
            import fitz
            self.pdf_methods.append('pymupdf')
        except ImportError:
            pass
    
    def extract_document_data(self, pdf_path):
        """Extract structured data from financial documents"""
        if 'pdfplumber' in self.pdf_methods:
            return self._extract_with_pdfplumber(pdf_path)
        elif 'pymupdf' in self.pdf_methods:
            return self._extract_with_pymupdf(pdf_path)
        else:
            raise Exception("No PDF processing libraries available")
    
    def _extract_with_pdfplumber(self, pdf_path):
        """Extract data using pdfplumber"""
        import pdfplumber
        extracted_data = []
        
        with pdfplumber.open(pdf_path) as pdf:
            for page_num, page in enumerate(pdf.pages):
                # Extract text content
                page_text = page.extract_text() or ""
                
                # Extract tables
                tables = []
                try:
                    page_tables = page.extract_tables()
                    if page_tables:
                        for table_idx, table in enumerate(page_tables):
                            if table and len(table) > 0:
                                table_df = pd.DataFrame(table[1:], columns=table[0] if table[0] else None)
                                tables.append({
                                    'table_id': table_idx,
                                    'data': table_df.to_dict('records'),
                                    'rows': len(table_df),
                                    'columns': len(table_df.columns)
                                })
                except Exception as e:
                    st.warning(f"Table extraction error on page {page_num + 1}: {str(e)}")
                
                # Extract financial metrics
                metrics = self._extract_financial_metrics(page_text)
                
                page_data = {
                    'page_number': page_num + 1,
                    'text_content': page_text,
                    'word_count': len(page_text.split()),
                    'character_count': len(page_text),
                    'tables': tables,
                    'financial_metrics': metrics,
                    'extraction_timestamp': datetime.now().isoformat()
                }
                
                extracted_data.append(page_data)
        
        return extracted_data
    
    def _extract_with_pymupdf(self, pdf_path):
        """Extract data using PyMuPDF"""
        import fitz
        extracted_data = []
        
        doc = fitz.open(pdf_path)
        for page_num in range(len(doc)):
            page = doc.load_page(page_num)
            page_text = page.get_text()
            
            # Extract financial metrics
            metrics = self._extract_financial_metrics(page_text)
            
            page_data = {
                'page_number': page_num + 1,
                'text_content': page_text,
                'word_count': len(page_text.split()),
                'character_count': len(page_text),
                'tables': [],  # PyMuPDF table extraction would require additional logic
                'financial_metrics': metrics,
                'extraction_timestamp': datetime.now().isoformat()
            }
            
            extracted_data.append(page_data)
        
        doc.close()
        return extracted_data
    
    def _extract_financial_metrics(self, text):
        """Extract basic financial metrics using pattern matching"""
        metrics = {}
        
        # Currency amounts
        currency_pattern = r'\$\s?(\d{1,3}(?:,\d{3})*(?:\.\d+)?)\s?(?:million|billion|M|B)?'
        currency_matches = re.findall(currency_pattern, text, re.IGNORECASE)
        metrics['currency_amounts'] = currency_matches
        
        # Percentages
        percentage_pattern = r'(\d+\.?\d*)\s?%'
        percentage_matches = re.findall(percentage_pattern, text)
        metrics['percentages'] = percentage_matches
        
        # Specific financial ratios
        ratio_patterns = {
            'CET1_Ratio': r'CET1.*?(\d+\.?\d*)\s?%',
            'Tier1_Ratio': r'Tier\s*1.*?(\d+\.?\d*)\s?%',
            'Leverage_Ratio': r'Leverage.*?(\d+\.?\d*)\s?%',
            'ROE': r'ROE.*?(\d+\.?\d*)\s?%',
            'ROA': r'ROA.*?(\d+\.?\d*)\s?%'
        }
        
        for ratio_name, pattern in ratio_patterns.items():
            matches = re.findall(pattern, text, re.IGNORECASE)
            if matches:
                metrics[ratio_name] = matches[0]  # Take first match
        
        return metrics
    
    def transform_to_dataframe(self, extracted_data):
        """Transform extracted data into structured DataFrame"""
        rows = []
        
        for page_data in extracted_data:
            # Base row with page-level data
            base_row = {
                'page_number': page_data['page_number'],
                'word_count': page_data['word_count'],
                'character_count': page_data['character_count'],
                'table_count': len(page_data['tables']),
                'extraction_timestamp': page_data['extraction_timestamp']
            }
            
            # Add financial metrics
            for metric_name, metric_value in page_data['financial_metrics'].items():
                if isinstance(metric_value, list):
                    base_row[f'metric_{metric_name}'] = '; '.join(metric_value)
                else:
                    base_row[f'metric_{metric_name}'] = metric_value
            
            # Add table data as separate rows or columns
            if page_data['tables']:
                for table in page_data['tables']:
                    table_row = base_row.copy()
                    table_row['table_id'] = table['table_id']
                    table_row['table_rows'] = table['rows']
                    table_row['table_columns'] = table['columns']
                    rows.append(table_row)
            else:
                rows.append(base_row)
        
        return pd.DataFrame(rows)
    
    def load_to_csv(self, dataframe, filename):
        """Load DataFrame to CSV format"""
        return dataframe.to_csv(index=False)

def install_pdfplumber():
    """Install pdfplumber if needed"""
    try:
        st.info("Installing pdfplumber...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", "pdfplumber"])
        st.success("Successfully installed pdfplumber")
        return True
    except Exception as e:
        st.error(f"Failed to install pdfplumber: {str(e)}")
        return False

def main():
    st.set_page_config(
        page_title="FinDocPipeline - Financial Document ETL",
        page_icon="üîÑ",
        layout="wide"
    )
    
    st.title("üîÑ FinDocPipeline - Financial Document ETL")
    st.markdown("**Pure Extract, Transform, Load pipeline for financial documents**")
    
    # Initialize ETL processor
    etl = FinancialDocumentETL()
    
    # Check capabilities
    if not etl.pdf_methods:
        st.warning("‚ö†Ô∏è ETL requires pdfplumber or PyMuPDF!")
        if st.button("üîß Install pdfplumber"):
            if install_pdfplumber():
                st.experimental_rerun()
        return
    else:
        st.success(f"‚úÖ ETL ready with: {', '.join(etl.pdf_methods)}")
    
    # File upload
    st.header("üìÅ Upload Financial Document")
    uploaded_file = st.file_uploader(
        "Choose a PDF file",
        type=['pdf'],
        help="Upload financial presentations, earnings reports, or regulatory filings"
    )
    
    if uploaded_file is not None:
        try:
            # Save PDF temporarily
            with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_path = tmp_file.name
            
            try:
                # EXTRACT
                with st.spinner("üîÑ Extracting data from document..."):
                    extracted_data = etl.extract_document_data(tmp_path)
                
                # TRANSFORM
                with st.spinner("üîÑ Transforming data to structured format..."):
                    structured_df = etl.transform_to_dataframe(extracted_data)
                
                # LOAD (prepare for output)
                with st.spinner("üîÑ Preparing data for export..."):
                    csv_data = etl.load_to_csv(structured_df, f"{uploaded_file.name}_etl_output.csv")
                
                st.success(f"‚úÖ ETL completed: {uploaded_file.name} ({len(extracted_data)} pages processed)")
                
                # Display results
                st.header("üìä ETL Results")
                
                # Summary metrics
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("Pages Processed", len(extracted_data))
                with col2:
                    total_words = sum(page['word_count'] for page in extracted_data)
                    st.metric("Total Words", f"{total_words:,}")
                with col3:
                    total_tables = sum(len(page['tables']) for page in extracted_data)
                    st.metric("Tables Found", total_tables)
                with col4:
                    st.metric("Output Rows", len(structured_df))
                
                # Data preview
                st.subheader("üìÑ Structured Data Preview")
                st.dataframe(structured_df.head(10), use_container_width=True)
                
                # Financial metrics summary
                metric_columns = [col for col in structured_df.columns if col.startswith('metric_')]
                if metric_columns:
                    st.subheader("üí∞ Financial Metrics Extracted")
                    metrics_summary = structured_df[['page_number'] + metric_columns].dropna(how='all', subset=metric_columns)
                    st.dataframe(metrics_summary, use_container_width=True)
                
                # Download options
                st.subheader("üíæ Export Data")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.download_button(
                        label="üìä Download CSV",
                        data=csv_data,
                        file_name=f"{uploaded_file.name}_etl_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv"
                    )
                
                with col2:
                    # JSON export option
                    json_data = structured_df.to_json(orient='records', indent=2)
                    st.download_button(
                        label="üìã Download JSON",
                        data=json_data,
                        file_name=f"{uploaded_file.name}_etl_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                        mime="application/json"
                    )
                
                # Technical details
                with st.expander("üîß ETL Pipeline Details"):
                    st.write("**Extract Phase:**")
                    st.write("- PDF text extraction using pdfplumber/PyMuPDF")
                    st.write("- Table structure detection and extraction")
                    st.write("- Financial metrics pattern matching")
                    
                    st.write("**Transform Phase:**")
                    st.write("- Data normalization and cleaning")
                    st.write("- Structured DataFrame creation")
                    st.write("- Metric aggregation and formatting")
                    
                    st.write("**Load Phase:**")
                    st.write("- CSV format generation")
                    st.write("- JSON format generation")
                    st.write("- Data validation and quality checks")
                    
                    st.write("**Processing Statistics:**")
                    avg_words = total_words / len(extracted_data) if extracted_data else 0
                    st.write(f"- Average words per page: {avg_words:.0f}")
                    st.write(f"- Processing method: {etl.pdf_methods[0]}")
                    st.write(f"- Total processing time: < 1 minute")
            
            finally:
                # Clean up temporary file
                try:
                    os.unlink(tmp_path)
                except:
                    pass
        
        except Exception as e:
            st.error(f"‚ùå ETL Error: {str(e)}")
            st.write("**Troubleshooting:**")
            st.write("- Ensure the PDF is not password-protected")
            st.write("- Try a different PDF file")
            st.write("- Check that the file is a valid PDF")

if __name__ == "__main__":
    main()