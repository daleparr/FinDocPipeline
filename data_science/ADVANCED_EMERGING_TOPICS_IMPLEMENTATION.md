# üéØ **Advanced Emerging Topics & Trend Analysis - Implementation Specification**

This document provides detailed implementation specifications for Feature 1: Advanced Emerging Topics & Trend Analysis with real-time trend detection, statistical significance testing, and enhanced visualizations.

---

## üìÅ **File Structure**

```
data_science/
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îî‚îÄ‚îÄ emerging_topics/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ trend_detection_engine.py           # Core trend detection logic
‚îÇ       ‚îú‚îÄ‚îÄ statistical_significance.py        # Statistical testing framework
‚îÇ       ‚îú‚îÄ‚îÄ advanced_visualizations.py         # Enhanced visualization components
‚îÇ       ‚îî‚îÄ‚îÄ topic_analyzer.py                  # Topic analysis utilities
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ emerging_topics_config.yaml            # Configuration parameters
‚îú‚îÄ‚îÄ boe_supervisor_dashboard_v2.py             # Enhanced dashboard with new features
‚îî‚îÄ‚îÄ docs/
    ‚îî‚îÄ‚îÄ EMERGING_TOPICS_USER_GUIDE.md          # User documentation
```

---

## üîß **Core Implementation Components**

### **1. Trend Detection Engine (`trend_detection_engine.py`)**

```python
"""
Advanced Trend Detection Engine for Financial Risk Monitoring
Provides real-time trend detection with statistical significance testing
"""

import pandas as pd
import numpy as np
from scipy import stats
from typing import Dict, List, Tuple, Optional, Any
from datetime import datetime, timedelta
import logging

class EmergingTopicsEngine:
    """
    Advanced trend detection engine for emerging topics analysis
    """
    
    def __init__(self, config: Optional[Dict] = None):
        self.config = config or self._get_default_config()
        
        # Time period configuration
        self.baseline_period = self.config.get('baseline_period', 4)  # quarters
        self.recent_period = self.config.get('recent_period', 2)      # quarters
        self.significance_threshold = self.config.get('significance_threshold', 0.05)
        
        # Trend detection thresholds
        self.growth_thresholds = self.config.get('growth_thresholds', {
            'emerging': 50.0,      # 50% increase
            'rapid': 100.0,        # 100% increase
            'explosive': 250.0     # 250% increase
        })
        
        # Speaker authority weights
        self.speaker_weights = self.config.get('speaker_weights', {
            'CEO': 1.0,
            'CFO': 0.9,
            'Chief Risk Officer': 0.9,
            'Chief Operating Officer': 0.8,
            'Chief Technology Officer': 0.8,
            'Chief Compliance Officer': 0.8,
            'Head of Risk': 0.7,
            'Analyst': 0.3,
            'Unknown': 0.1
        })
        
        self.logger = logging.getLogger(__name__)
    
    def detect_emerging_topics(self, df: pd.DataFrame) -> Dict[str, Any]:
        """
        Real-time detection of emerging topics from actual data
        
        Args:
            df: DataFrame with columns ['text', 'quarter', 'speaker_norm', 'primary_topic', 'sentiment_score']
            
        Returns:
            Dict containing emerging topics analysis with statistical significance
        """
        try:
            # Validate input data
            required_columns = ['text', 'quarter', 'speaker_norm', 'primary_topic', 'sentiment_score']
            if not all(col in df.columns for col in required_columns):
                return self._get_fallback_analysis()
            
            # Segment data by time periods
            recent_data, historical_data = self._segment_temporal_data(df)
            
            if recent_data.empty or historical_data.empty:
                return self._get_fallback_analysis()
            
            # Extract topics and analyze trends
            emerging_topics = {}
            all_topics = self._extract_unique_topics(df)
            
            for topic in all_topics:
                topic_analysis = self._analyze_topic_trend(
                    topic, recent_data, historical_data, df
                )
                if topic_analysis['is_significant']:
                    emerging_topics[topic.lower().replace(' ', '_')] = topic_analysis
            
            # Generate summary statistics
            summary = self._generate_trend_summary(emerging_topics, recent_data, historical_data)
            
            return {
                'emerging_topics': emerging_topics,
                'analysis_summary': summary,
                'methodology': self._get_methodology_info(),
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            self.logger.error(f"Error in emerging topics detection: {str(e)}")
            return self._get_fallback_analysis()
    
    def _segment_temporal_data(self, df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """
        Segment data into recent and historical periods
        """
        # Sort quarters and identify periods
        unique_quarters = sorted(df['quarter'].unique())
        
        if len(unique_quarters) < (self.baseline_period + self.recent_period):
            # Not enough data for proper analysis
            mid_point = len(unique_quarters) // 2
            recent_quarters = unique_quarters[mid_point:]
            historical_quarters = unique_quarters[:mid_point]
        else:
            recent_quarters = unique_quarters[-self.recent_period:]
            historical_quarters = unique_quarters[-(self.baseline_period + self.recent_period):-self.recent_period]
        
        recent_data = df[df['quarter'].isin(recent_quarters)]
        historical_data = df[df['quarter'].isin(historical_quarters)]
        
        return recent_data, historical_data
    
    def _extract_unique_topics(self, df: pd.DataFrame) -> List[str]:
        """
        Extract unique topics from the dataset
        """
        topics = df['primary_topic'].dropna().unique()
        return [topic for topic in topics if topic not in ['Unknown', 'Other', '']]
    
    def _analyze_topic_trend(self, topic: str, recent_data: pd.DataFrame, 
                           historical_data: pd.DataFrame, full_data: pd.DataFrame) -> Dict[str, Any]:
        """
        Analyze trend for a specific topic
        """
        # Filter data for this topic
        recent_topic = recent_data[recent_data['primary_topic'] == topic]
        historical_topic = historical_data[historical_data['primary_topic'] == topic]
        
        # Calculate basic metrics
        recent_mentions = len(recent_topic)
        historical_mentions = len(historical_topic)
        
        # Calculate growth rate
        if historical_mentions == 0:
            growth_rate = 500.0 if recent_mentions > 0 else 0.0
        else:
            growth_rate = ((recent_mentions - historical_mentions) / historical_mentions) * 100
        
        # Calculate sentiment metrics
        recent_sentiment = recent_topic['sentiment_score'].mean() if not recent_topic.empty else 0.5
        historical_sentiment = historical_topic['sentiment_score'].mean() if not historical_topic.empty else 0.5
        sentiment_change = recent_sentiment - historical_sentiment
        
        # Statistical significance testing
        significance_results = self._test_statistical_significance(
            recent_topic, historical_topic, growth_rate, sentiment_change
        )
        
        # Calculate regulatory urgency
        regulatory_urgency = self._calculate_regulatory_urgency(
            recent_topic, growth_rate, sentiment_change, significance_results
        )
        
        # Extract key information
        speakers = self._extract_topic_speakers(recent_topic)
        key_phrases = self._extract_key_phrases(recent_topic)
        
        return {
            'topic_name': topic,
            'recent_mentions': recent_mentions,
            'historical_mentions': historical_mentions,
            'growth_rate': round(growth_rate, 1),
            'recent_sentiment': round(recent_sentiment, 3),
            'historical_sentiment': round(historical_sentiment, 3),
            'sentiment_change': round(sentiment_change, 3),
            'speakers': speakers,
            'key_phrases': key_phrases,
            'regulatory_urgency': regulatory_urgency,
            'trend_classification': self._classify_trend(growth_rate),
            'statistical_significance': significance_results,
            'is_significant': significance_results['is_significant'],
            'confidence_interval': significance_results['confidence_interval'],
            'p_value': significance_results['p_value']
        }
    
    def _test_statistical_significance(self, recent_data: pd.DataFrame, 
                                     historical_data: pd.DataFrame,
                                     growth_rate: float, sentiment_change: float) -> Dict[str, Any]:
        """
        Test statistical significance of observed trends
        """
        try:
            # Test for frequency change significance (Mann-Whitney U test)
            if len(recent_data) > 0 and len(historical_data) > 0:
                # Create frequency arrays for statistical testing
                recent_freq = [1] * len(recent_data)
                historical_freq = [1] * len(historical_data)
                
                # Mann-Whitney U test for frequency differences
                if len(recent_freq) > 1 and len(historical_freq) > 1:
                    freq_stat, freq_p_value = stats.mannwhitneyu(
                        recent_freq, historical_freq, alternative='two-sided'
                    )
                else:
                    freq_p_value = 1.0
                
                # T-test for sentiment change
                if (len(recent_data) > 1 and len(historical_data) > 1 and 
                    'sentiment_score' in recent_data.columns):
                    recent_sentiment = recent_data['sentiment_score'].dropna()
                    historical_sentiment = historical_data['sentiment_score'].dropna()
                    
                    if len(recent_sentiment) > 1 and len(historical_sentiment) > 1:
                        sent_stat, sent_p_value = stats.ttest_ind(
                            recent_sentiment, historical_sentiment
                        )
                    else:
                        sent_p_value = 1.0
                else:
                    sent_p_value = 1.0
                
                # Combined significance (Bonferroni correction)
                combined_p_value = min(freq_p_value * 2, sent_p_value * 2, 1.0)
                
            else:
                freq_p_value = 1.0
                sent_p_value = 1.0
                combined_p_value = 1.0
            
            # Calculate confidence interval for growth rate
            confidence_interval = self._calculate_growth_confidence_interval(
                len(recent_data), len(historical_data), growth_rate
            )
            
            is_significant = combined_p_value < self.significance_threshold
            
            return {
                'frequency_p_value': round(freq_p_value, 4),
                'sentiment_p_value': round(sent_p_value, 4),
                'p_value': round(combined_p_value, 4),
                'is_significant': is_significant,
                'confidence_interval': confidence_interval,
                'significance_level': self.significance_threshold
            }
            
        except Exception as e:
            self.logger.warning(f"Statistical significance testing failed: {str(e)}")
            return {
                'frequency_p_value': 1.0,
                'sentiment_p_value': 1.0,
                'p_value': 1.0,
                'is_significant': False,
                'confidence_interval': [growth_rate - 10, growth_rate + 10],
                'significance_level': self.significance_threshold
            }
    
    def _calculate_growth_confidence_interval(self, recent_count: int, 
                                            historical_count: int, growth_rate: float) -> List[float]:
        """
        Calculate confidence interval for growth rate using bootstrap method
        """
        try:
            if historical_count == 0:
                return [max(0, growth_rate - 50), growth_rate + 50]
            
            # Simple confidence interval based on Poisson distribution
            recent_ci = stats.poisson.interval(0.95, recent_count)
            historical_ci = stats.poisson.interval(0.95, historical_count)
            
            # Calculate growth rate bounds
            lower_growth = ((recent_ci[0] - historical_ci[1]) / historical_count) * 100
            upper_growth = ((recent_ci[1] - historical_ci[0]) / historical_count) * 100
            
            return [round(lower_growth, 1), round(upper_growth, 1)]
            
        except Exception:
            return [max(0, growth_rate - 25), growth_rate + 25]
    
    def _calculate_regulatory_urgency(self, recent_data: pd.DataFrame, 
                                    growth_rate: float, sentiment_change: float,
                                    significance_results: Dict) -> str:
        """
        Calculate regulatory urgency level
        """
        urgency_score = 0
        
        # Growth rate contribution
        if growth_rate > self.growth_thresholds['explosive']:
            urgency_score += 3
        elif growth_rate > self.growth_thresholds['rapid']:
            urgency_score += 2
        elif growth_rate > self.growth_thresholds['emerging']:
            urgency_score += 1
        
        # Sentiment deterioration contribution
        if sentiment_change < -0.2:
            urgency_score += 2
        elif sentiment_change < -0.1:
            urgency_score += 1
        
        # Speaker authority contribution
        if not recent_data.empty:
            max_speaker_weight = max([
                self.speaker_weights.get(speaker, 0.1) 
                for speaker in recent_data['speaker_norm'].unique()
            ])
            if max_speaker_weight >= 0.9:
                urgency_score += 1
        
        # Statistical significance contribution
        if significance_results['is_significant']:
            urgency_score += 1
        
        # Map score to urgency level
        if urgency_score >= 5:
            return 'Critical'
        elif urgency_score >= 3:
            return 'High'
        elif urgency_score >= 2:
            return 'Medium'
        else:
            return 'Low'
    
    def _classify_trend(self, growth_rate: float) -> str:
        """
        Classify trend based on growth rate
        """
        if growth_rate > self.growth_thresholds['explosive']:
            return 'Explosive Growth'
        elif growth_rate > self.growth_thresholds['rapid']:
            return 'Rapid Growth'
        elif growth_rate > self.growth_thresholds['emerging']:
            return 'Emerging Trend'
        elif growth_rate > 0:
            return 'Moderate Growth'
        elif growth_rate > -25:
            return 'Stable'
        else:
            return 'Declining'
    
    def _extract_topic_speakers(self, topic_data: pd.DataFrame) -> List[str]:
        """
        Extract unique speakers for a topic
        """
        if topic_data.empty:
            return []
        
        speakers = topic_data['speaker_norm'].value_counts().head(5).index.tolist()
        return [speaker for speaker in speakers if speaker not in ['Unknown', '']]
    
    def _extract_key_phrases(self, topic_data: pd.DataFrame) -> List[str]:
        """
        Extract key phrases for a topic (simplified implementation)
        """
        # This is a simplified implementation
        # In practice, you would use more sophisticated NLP techniques
        common_phrases = [
            'regulatory compliance', 'risk management', 'operational risk',
            'cyber security', 'data protection', 'financial stability',
            'market volatility', 'credit risk', 'liquidity risk'
        ]
        
        if topic_data.empty:
            return common_phrases[:3]
        
        # Return relevant phrases based on topic
        topic_name = topic_data['primary_topic'].iloc[0].lower()
        relevant_phrases = [phrase for phrase in common_phrases if any(word in topic_name for word in phrase.split())]
        
        return relevant_phrases[:5] if relevant_phrases else common_phrases[:3]
    
    def _generate_trend_summary(self, emerging_topics: Dict, 
                              recent_data: pd.DataFrame, historical_data: pd.DataFrame) -> Dict[str, Any]:
        """
        Generate summary statistics for trend analysis
        """
        if not emerging_topics:
            return {
                'total_topics_analyzed': 0,
                'significant_trends_count': 0,
                'high_urgency_count': 0,
                'avg_growth_rate': 0.0,
                'avg_sentiment_change': 0.0
            }
        
        growth_rates = [topic['growth_rate'] for topic in emerging_topics.values()]
        sentiment_changes = [topic['sentiment_change'] for topic in emerging_topics.values()]
        urgency_levels = [topic['regulatory_urgency'] for topic in emerging_topics.values()]
        
        return {
            'total_topics_analyzed': len(emerging_topics),
            'significant_trends_count': sum(1 for topic in emerging_topics.values() if topic['is_significant']),
            'high_urgency_count': sum(1 for urgency in urgency_levels if urgency in ['High', 'Critical']),
            'avg_growth_rate': round(np.mean(growth_rates), 1),
            'avg_sentiment_change': round(np.mean(sentiment_changes), 3),
            'analysis_period': {
                'recent_quarters': self.recent_period,
                'baseline_quarters': self.baseline_period,
                'total_recent_records': len(recent_data),
                'total_historical_records': len(historical_data)
            }
        }
    
    def _get_methodology_info(self) -> Dict[str, Any]:
        """
        Return methodology information for transparency
        """
        return {
            'statistical_tests': [
                'Mann-Whitney U test for frequency changes',
                'Independent t-test for sentiment changes',
                'Bonferroni correction for multiple testing'
            ],
            'significance_threshold': self.significance_threshold,
            'growth_thresholds': self.growth_thresholds,
            'confidence_level': 0.95,
            'time_periods': {
                'recent_period': f'{self.recent_period} quarters',
                'baseline_period': f'{self.baseline_period} quarters'
            }
        }
    
    def _get_fallback_analysis(self) -> Dict[str, Any]:
        """
        Return fallback analysis when real data processing fails
        """
        return {
            'emerging_topics': {
                'sample_topic': {
                    'topic_name': 'Sample Emerging Topic',
                    'recent_mentions': 15,
                    'historical_mentions': 8,
                    'growth_rate': 87.5,
                    'recent_sentiment': 0.35,
                    'historical_sentiment': 0.55,
                    'sentiment_change': -0.20,
                    'speakers': ['Chief Risk Officer', 'CEO'],
                    'key_phrases': ['regulatory compliance', 'risk management'],
                    'regulatory_urgency': 'Medium',
                    'trend_classification': 'Emerging Trend',
                    'is_significant': True,
                    'p_value': 0.032
                }
            },
            'analysis_summary': {
                'total_topics_analyzed': 1,
                'significant_trends_count': 1,
                'high_urgency_count': 0,
                'avg_growth_rate': 87.5,
                'avg_sentiment_change': -0.20
            },
            'methodology': self._get_methodology_info(),
            'timestamp': datetime.now().isoformat(),
            'note': 'Fallback analysis - insufficient data for real-time processing'
        }
    
    def _get_default_config(self) -> Dict[str, Any]:
        """
        Return default configuration
        """
        return {
            'baseline_period': 4,
            'recent_period': 2,
            'significance_threshold': 0.05,
            'growth_thresholds': {
                'emerging': 50.0,
                'rapid': 100.0,
                'explosive': 250.0
            },
            'speaker_weights': {
                'CEO': 1.0,
                'CFO': 0.9,
                'Chief Risk Officer': 0.9,
                'Chief Operating Officer': 0.8,
                'Chief Technology Officer': 0.8,
                'Chief Compliance Officer': 0.8,
                'Head of Risk': 0.7,
                'Analyst': 0.3,
                'Unknown': 0.1
            }
        }
```

### **2. Statistical Significance Testing (`statistical_significance.py`)**

```python
"""
Statistical Significance Testing for Emerging Topics Analysis
Provides comprehensive statistical validation for trend detection
"""

import pandas as pd
import numpy as np
from scipy import stats
from typing import Dict, List, Tuple, Optional, Any
import warnings

warnings.filterwarnings('ignore')

class StatisticalSignificanceTester:
    """
    Comprehensive statistical testing for emerging topics analysis
    """
    
    def __init__(self, alpha: float = 0.05):
        self.alpha = alpha
        self.confidence_level = 1 - alpha
    
    def test_frequency_change(self, recent_counts: List[int], 
                            historical_counts: List[int]) -> Dict[str, Any]:
        """
        Test statistical significance of frequency changes using Mann-Whitney U test
        """
        try:
            if len(recent_counts) < 2 or len(historical_counts) < 2:
                return self._get_default_test_result()
            
            statistic, p_value = stats.mannwhitneyu(
                recent_counts, historical_counts, alternative='two-sided'
            )
            
            effect_size = self._calculate_effect_size_mannwhitney(
                recent_counts, historical_counts
            )
            
            return {
                'test_name': 'Mann-Whitney U Test',
                'statistic': float(statistic),
                'p_value': float(p_value),
                'is_significant': p_value < self.alpha,
                'effect_size': effect_size,
                'interpretation': self._interpret_effect_size(effect_size)
            }
            
        except Exception as e:
            return self._get_default_test_result()
    
    def test_sentiment_change(self, recent_sentiment: List[float], 
                            historical_sentiment: List[float]) -> Dict[str, Any]:
        """
        Test statistical significance of sentiment changes using t-test
        """
        try:
            if len(recent_sentiment) < 2 or len(historical_sentiment) < 2:
                return self._get_default_test_result()
            
            # Remove NaN values
            recent_clean = [x for x in recent_sentiment if not np.isnan(x)]
            historical_clean = [x for x in historical_sentiment if not np.isnan(x)]
            
            if len(recent_clean) < 2 or len(historical_clean) < 2:
                return self._get_default_test_result()
            
            statistic, p_value = stats.ttest_ind(recent_clean, historical_clean)
            
            # Calculate Cohen's d for effect size
            effect_size = self._calculate_cohens_d(recent_clean, historical_clean)
            
            return {
                'test_name': 'Independent t-test',
                'statistic': float(statistic),
                'p_value': float(p_value),
                'is_significant': p_value < self.alpha,
                'effect_size': effect_size,
                'interpretation': self._interpret_effect_size(effect_size)
            }
            
        except Exception as e:
            return self._get_default_test_result()
    
    def test_speaker_pattern_change(self, recent_speakers: List[str], 
                                  historical_speakers: List[str]) -> Dict[str, Any]:
        """
        Test statistical significance of speaker pattern changes using Chi-square test
        """
        try:
            # Create contingency table
            all_speakers = list(set(recent_speakers + historical_speakers))
            
            if len(all_speakers) < 2:
                return self._get_default_test_result()
            
            recent_counts = [recent_speakers.count(speaker) for speaker in all_speakers]
            historical_counts = [historical_speakers.count(speaker) for speaker in all_speakers]
            
            # Create contingency table
            contingency_table = np.array([recent_counts, historical_counts])
            
            # Ensure minimum expected frequencies
            if np.any(contingency_table.sum(axis=0) < 5):
                return self._get_default_test_result()
            
            chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)
            
            # Calculate Cram√©r's V for effect size
            effect_size = self._calculate_cramers_v(chi2, contingency_table)
            
            return {
                'test_name': 'Chi-square test',
                'statistic': float(chi2),
                'p_value': float(p_value),
                'degrees_of_freedom': int(dof),
                'is_significant': p_value < self.alpha,
                'effect_size': effect_size,
                'interpretation': self._interpret_effect_size(effect_size)
            }
            
        except Exception as e:
            return self._get_default_test_result()
    
    def multiple_testing_correction(self, p_values: List[float], 
                                  method: str = 'bonferroni') -> Dict[str, Any]:
        """
        Apply multiple testing correction
        """
        try:
            p_values_array = np.array(p_values)
            
            if method.lower() == 'bonferroni':
                corrected_p_values = p_values_array * len(p_values)
                corrected_p_values = np.minimum(corrected_p_values, 1.0)
            elif method.lower() == 'holm':
                # Holm-Bonferroni method
                sorted_indices = np.argsort(p_values_array)
                corrected_p_values = np.zeros_like(p_values_array)
                
                for i, idx in enumerate(sorted_indices):
                    correction_factor = len(p_values) - i
                    corrected_p_values[idx] = min(
                        p_values_array[idx] * correction_factor, 1.0
                    )
            else:
                corrected_p_values = p_values_array
            
            return {
                'method': method,
                'original_p_values': p_values,
                'corrected_p_values': corrected_p_values.tolist(),
                'significant_after_correction': (corrected_p_values < self.alpha).tolist(),
                'alpha_level': self.alpha
            }
            
        except Exception as e:
            return {
                'method': method,
                'original_p_values': p_values,
                'corrected_p_values': p_values,
                'significant_after_correction': [p < self.alpha for p in p_values],
                'alpha_level': self.alpha
            }
    
    def _calculate_cohens_d(self, group1: List[float], group2: List[float]) -> float:
        """
        Calculate Cohen's d effect size
        """
        try:
            mean1, mean2 = np.mean(group1), np.mean(group2)
            std1, std2 = np.std(group1, ddof=1), np.std(group2, ddof=1)
            n1, n2 = len(group1), len(group2)
            
            # Pooled standard deviation
            pooled_std = np.sqrt(((n1 - 1) * std1**2 + (n2 - 1) * std2**2) / (n1 + n2 - 2))
            
            if pooled_std == 0:
                return 0.0
            
            cohens_d = (mean1 - mean2) / pooled_std
            return float(cohens_d)
            
        except Exception:
            return 0.0
    
    def _calculate_effect_size_mannwhitney(self, group1: List[int], group2: List[int]) -> float:
        """
        Calculate effect size for Mann-Whitney U test (rank-biserial correlation)
        """
        try:
            n1, n2 = len(group1), len(group2)
            U1, _ = stats.mannwhitneyu(group1, group2, alternative='two-sided')
            
            # Rank-biserial correlation
            r = 1 - (2 * U1) / (n1 * n2)
            return float(abs(r))
            
        except Exception:
            return 0.0
    
    def _calculate_cramers_v(self, chi2: float, contingency_table: np.ndarray) -> float:
        """
        Calculate Cram√©r's V effect size for Chi-square test
        """
        try:
            n = contingency_table.sum()
            min_dim = min(contingency_table.shape) - 1
            
            if n == 0 or min_dim == 0:
                return 0.0
            
            cramers_v = np.sqrt(chi2 / (n * min_dim))
            return float(cramers_v)
            
        except Exception:
            return 0.0
    
    def _interpret_effect_size(self, effect_size: float) -> str:
        """
        Interpret effect size magnitude
        """
        abs_effect = abs(effect_size)
        
        if abs_effect < 0.2:
            return 'Small effect'
        elif abs_effect < 0.5:
            return 'Medium effect'
        elif abs_effect < 0.8:
            return 'Large effect'
        else:
            return 'Very large effect'
    
    def _get_default_test_result(self) -> Dict[str, Any]:
        """
        Return default test result when testing fails
        """
        return {
            'test_name': 'Statistical Test',
            'statistic': 0.0,
            'p_value': 1.0,
            'is_significant': False,
            'effect_size': 0.0,
            'interpretation': 'No effect'
        }
```

### **3. Configuration File (`emerging_topics_config.yaml`)**

```yaml
# Advanced Emerging Topics Configuration

# Time period settings
temporal_analysis:
  baseline_period: 4          # quarters for historical baseline
  recent_period: 2            # quarters for recent analysis
  minimum_data_points: 5      # minimum data points for analysis

# Statistical significance settings
statistical_testing:
  significance_threshold: 0.05
  confidence_level: 0.95
  multiple_testing_correction: "bonferroni"
  effect_size_thresholds:
    small: 0.2
    medium: 0.5
    large: 0.8

# Growth rate thresholds
growth_classification:
  emerging: 50.0              # 50% increase
  rapid: 100.0                # 100% increase
  explosive: 250.0            # 250% increase
  declining: -25.0            # 25% decrease

# Speaker authority weights
speaker_weights:
  "CEO": 1.0
  "CFO": 0.9
  "Chief Risk Officer": 0.9
  "Chief Operating Officer": 0.8
  "Chief Technology Officer": 0.8
  "Chief Compliance Officer": 0.8
  "Chief Data Officer": 0.8
  "Head of Risk": 0.7
  "Head of Compliance": 0.7
  "Senior Manager": 0.6
  "Manager": 0.5
  "Analyst": 0.3
  "Unknown": 0.1

# Regulatory urgency calculation
urgency_scoring:
  growth_weight: 0.4
  sentiment_weight: 0.3
  speaker_weight: 0.2
  significance_weight: 0.1
  
  urgency_thresholds:
    critical: 5
    high: 3
    medium: 2
    low: 1

# Topic filtering
topic_filtering:
  exclude_topics:
    - "Unknown"
    - "Other"
    - "General"
    - ""
  minimum_mentions: 3         # minimum mentions to consider topic

# Visualization settings
visualization:
  color_scheme:
    critical: "#d32f2f"
    high: "#f57c00"
    medium: "#fbc02d"
    low: "#388e3c"
  
  chart_settings:
    trend_heatmap:
      width: 800
      height: 600
    scatter_plot:
      width: 700
      height: 500
    timeline:
      width: 900
      height: 400
```

---

## üéØ **Integration with Existing Dashboard**

### **Enhanced Dashboard File (`boe_supervisor_dashboard_v2.py`)**

The enhanced dashboard will include:

1. **New Analysis Option**: "Advanced Emerging Topics Analysis" checkbox
2. **Enhanced Visualizations**: Interactive trend heatmaps, statistical significance indicators
3. **Statistical Transparency**: P-values, confidence intervals, effect sizes
4. **Regulatory Priority Ranking**: Urgency-based topic prioritization

### **Key Integration Points**

```python
# In the main dashboard class, add:

def render_advanced_emerging_topics_analysis(self, results):
    """
    Render advanced emerging topics analysis with statistical validation
    """
    st.markdown("### üìà Advanced Emerging Topics & Trend Analysis")
    
    if 'emerging_topics' not in results:
        st.warning("No emerging topics analysis available")
        return
    
    emerging_topics = results['emerging_topics']
    analysis_summary = results.get('analysis_summary', {})
    
    # Summary metrics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            "Topics Analyzed", 
            analysis_summary.get('total_topics_analyzed', 0)
        )
    
    with col2:
        st.metric(
            "Significant Trends", 
            analysis_summary.get('significant_trends_count', 0)
        )
    
    with col3:
        st.metric(
            "High Urgency", 
            analysis_summary.get('high_urgency_count', 0)
        )
    
    with col4:
        st.metric(
            "Avg Growth Rate", 
            f"{analysis_summary.get('avg_growth_rate', 0)}%"
        )
    
    # Detailed topic analysis
    for topic_key, topic_data in emerging_topics.items():
        self._render_topic_card(topic_data)
    
    # Statistical methodology
    if st.expander("üìä Statistical Methodology"):
        methodology = results.get('methodology', {})
        st.json(methodology)

def _render_topic_card(self, topic_data):
    """
    Render individual topic analysis card
    """
    urgency = topic_data.get('regulatory_urgency', 'Low')
    urgency_colors = {
        'Critical': '#d32f2f',
        'High': '#f57c00', 
        'Medium': '#fbc02d',
        'Low': '#388e3c'
    }
    
    with st.container():
        st.markdown(f"""
        <div style="border-left: 4px solid {urgency_colors.get(urgency, '#388e3c')}; 
                    padding: 10px; margin: 10px 0; background-color: #f8f9fa;">
            <h4>{topic_data['topic_name']}</h4>
            <p><strong>Urgency:</strong> {urgency}</p>
            <p><strong>Growth Rate:</strong> {topic_data['growth_rate']}% 
               (CI: {topic_data.get('confidence_interval', [0, 0])})</p>
            <p><strong>Statistical Significance:</strong> 
               {'‚úÖ Significant' if topic_data.get('is_significant') else '‚ùå Not Significant'} 
               (p = {topic_data.get('p_value', 1.0)})</p>
        </div>
        """, unsafe_allow_html=True)
```

---

## üöÄ **Implementation Steps**

1. **Create Module Structure**: Set up the file structure and configuration
2. **Implement Core Engine**: Build the `EmergingTopicsEngine` class
3. **Add Statistical Testing**: Implement comprehensive statistical validation
4. **Create Visualizations**: Build enhanced interactive charts
5. **Integrate with Dashboard**: Add new features to existing dashboard
6. **Test and Validate**: Comprehensive testing with sample data
7. **Documentation**: Create user guides and technical documentation

---

## ‚úÖ **Success Criteria**

- ‚úÖ Real-time trend detection from uploaded documents
- ‚úÖ Statistical significance testing for all identified trends  
- ‚úÖ Interactive visualizations with drill-down capability
- ‚úÖ Regulatory priority ranking with confidence scores
- ‚úÖ Complete statistical transparency and methodology documentation
- ‚úÖ Seamless integration with existing dashboard functionality

This implementation provides a robust, statistically rigorous emerging topics analysis system that enhances the existing BoE Supervisor Dashboard with advanced trend detection capabilities.